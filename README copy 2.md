-------------
선형이란?
https://www.youtube.com/watch?v=RhoBZ8RgQHg

선형이란 결과가 어떻게 일어날지 예측이 가능하다.
-> 연산의 결과가 예측이 가능하다.
--------------
기저란?
좌표의 축 역활을 해주는 벡터의 집합 
https://www.youtube.com/watch?v=S56pnD-geDQ

------------

벡터의 정사영 (projection)
정사영 : 선이나 어떤 도형에 빛을 빛추었을때 수직인 평면에 그려지는 그림자

https://gaussian37.github.io/math-la-projection/


https://www.youtube.com/watch?v=YEdscCNsinU&t=184s

---------------------

공분산
https://www.youtube.com/watch?v=X564toU2riA
https://yonghyuc.wordpress.com/2019/07/13/covariance-matrix-%EA%B3%B5%EB%B6%84%EC%82%B0-%ED%96%89%EB%A0%AC/
둘사이의 
Cov(x, y) > 0 이면 x가 증가할 때 y 도 증가,
Cov(x, y) < 0 이면 x가 증가할 때 y 는 감소 한다.

-----------------
행렬식 & 역행렬
https://www.youtube.com/watch?v=2bv_7QzBS4Y

선형변환 될 때 단위면적이 얼마만큼 늘어나는가? 
ad-bc

역행렬이란


-----------------
고윳값과 고유벡터의 의미
https://www.youtube.com/watch?v=7dmV3p3Iy90
https://www.youtube.com/watch?v=-L0y6nPQFcM


선형 행렬 A가 벡터 x와 평행할때는 관찰


벡터와 행렬을 곱하면 선형 변환이 이루어진다.
그런데 어떤 벡터들은 선형 변환 시 크기만 바뀌고, 방향이 안바뀌는 경우가 있음

입력 벡터 x를 A로 선형변환 시키고 Ax가 상수배라는 의미
그럼 그 상수배는 얼마인가? -> 고유값

--------------------------
특이값 분해 SVD
https://www.youtube.com/watch?v=vxJ1MzfvL5w

목적
- 행렬의 크기 감소
- 정방행렬이 아닌 행렬의 해를 구할 수 있게 해준다.
- 데이터 크기를 줄임

특징 
U



----------------------

PCA 
차원을 줄임
공분산 행렬 계산을 보니 트랜스 포머랑 비슷










