{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# https://www.youtube.com/watch?v=ovB0ddFtzzA&t=876s\n",
    "\n",
    "class patchembed(nn.Module):\n",
    "    \"\"\" 원본이미지 -> 패치이미지로 만듬 패치 이미지 임베드\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    img_size : int\n",
    "        이미지의 사이즈 (정사각형)\n",
    "        변수값 들어갈때는 (img_size,img_size)로 들어감\n",
    "    \n",
    "    patch_size : int\n",
    "        패치가 될 사이즈\n",
    "        변수값 들어갈때는 (patch_size,patch_size)로 들어감\n",
    "    \n",
    "    int_chans : int\n",
    "        입력이미지 채널수\n",
    "        \n",
    "    embed_dim : int\n",
    "        임베딩할 차원\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,img_size,patch_size,int_chans=3,embed_dim=768) -> None:\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        ## 패치 갯수\n",
    "        self.n_patches = (img_size // patch_size)**2\n",
    "\n",
    "        self.proj = nn.Conv2d(int_chans,embed_dim,kernel_size=patch_size,stride=patch_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\" 피드포워드 계산\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        x : torch.Tensor\n",
    "            모양 '(배치,채널수,이미지사이즈,이미지사이즈)'\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            모양 '(배치,패치갯수,임베딩 차원)'\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.proj(x)\n",
    "        x = x.flatten(2) # (배치,임배딩차원수,패치수)\n",
    "        x = x.transpose(1,2) # (배치,패치수,임배딩차원수)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    \"\"\" 어텐션 메커니즘\n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        인풋 차원\n",
    "        \n",
    "    n_heads : int\n",
    "        어텐션 메카니즘 헤더 갯수\n",
    "\n",
    "    qkv_bias : bool\n",
    "        쿼리,키,벨류 바이어스 변수 설정할건지\n",
    "        \n",
    "    attn_p : float\n",
    "        드롭아웃 확률 (쿼리,키,벨류)\n",
    "    \n",
    "    proj_p : float\n",
    "        드롭아웃 확률 (출력 텐서)    \n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    scale : float\n",
    "        노멀라이징 \n",
    "    qkv : nn.Linear\n",
    "        키,쿼리,벨류\n",
    "        \n",
    "    proj : nn.Linear\n",
    "        어텐션 값들 덴스레이어\n",
    "        \n",
    "    attn_drop, proj_drop : nn.Dropout\n",
    "        드롭아웃 레이어    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dim,n_heads=12,qkv_bias=True,attn_p=0.,proj_p=0.) -> None:\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // n_heads # 멀티헤드 어텐션 헤드는... 인코더의 전체차원에서 n_heads만큼 나누어줌\n",
    "        self.scale = self.head_dim ** -0.5 ## 어텐션 벡터 스케일링\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.query = nn.Linear(dim, dim)\n",
    "        self.key = nn.Linear(dim, dim)\n",
    "        self.value = nn.Linear(dim, dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.qkv = nn.Linear(dim,dim*3,bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "        self.proj = nn.Linear(dim,dim) ## 멀티헤더 어텐션은 입력,출력 차원의 갯수는 똑같음\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\" 전방향 연산 시작, (멀티헤더 어텐션은 입력,출력 차원의 갯수는 똑같음)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            모양 '(배치,패치수+1,dim)'\n",
    "            패치수+1은 앞에 클래스 토큰\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            모양 '(배치,패치수+1,dim)'\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ## 배치수, 패치수, x의 차원\n",
    "        ## 여기서 패치수는 임베딩된 벡터라 하나의 토큰으로 보아도 무방함\n",
    "        n_samples, n_tokens, dim = x.shape\n",
    "        \n",
    "        \n",
    "        ## 멀티헤더 셀프 어텐션은 입력과 출력의 차원이 같아야하는데 맞지 않다면 오류임 \n",
    "        if dim != self.dim:\n",
    "            raise ValueError\n",
    "        \n",
    "\n",
    "        ## qkv를 한꺼번에 계산 -> 리쉐이프\n",
    "        qkv = self.qkv(x) # (배치,패치+1,3*dim)\n",
    "\n",
    "                \n",
    "\n",
    "        qkv = qkv.reshape(n_samples,n_tokens,3,self.n_heads,self.head_dim) # (배치,패치수+1,3,해더수,해더 차원)\n",
    "        qkv = qkv.permute(2,0,3,1,4) # (3,배치,해더수,패치수+1,해더 차원)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## 쿼리,키,벨류 값 가져오기\n",
    "        q,k,v = qkv[0],qkv[1],qkv[2]\n",
    "        \n",
    "        ## 키값 ??? \n",
    "        k_t = k.transpose(-2,-1) # (배치,해더수,해더차원,패치수+1)\n",
    "        \n",
    "        ## 두행렬을 곱하고 스케일 조정\n",
    "        dp = (q@k_t) * self.scale # (배치,해더수,패치수+1,패치수+1)\n",
    "        \n",
    "        \n",
    "        ## 어텐션 맵 만듬 (소프트 맥스 & 드롭아웃)\n",
    "        attn = dp.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        \n",
    "        \n",
    "        weighted_avg = attn @ v # (배치,해더수,패치수+1,해더차원)\n",
    "        weighted_avg = weighted_avg.transpose(1,2) # (배치,패치수+1,해더수,해더차원)\n",
    "        weighted_avg = weighted_avg.flatten(2) # (배치,패치수+1,)\n",
    "        \n",
    "        x = self.proj(weighted_avg)\n",
    "        x = self.proj_drop(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    \"\"\" 멀티 레이어\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_features: int\n",
    "        입력데이터 사이즈\n",
    "        \n",
    "    hidden_feactures : int\n",
    "        히든 레이어 갯수\n",
    "    \n",
    "    out_feactures : int\n",
    "        출력 사이즈\n",
    "    \n",
    "    p : float\n",
    "        드롭아웃 확률\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self,in_features,hidden_feactures,out_feactures,p=0.):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,hidden_feactures)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_feactures,out_feactures)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class Block(nn.Module):\n",
    "    \"\"\" 트랜스 포머 블럭\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim : int\n",
    "        임베딩 차원\n",
    "    \n",
    "    n_heads : int\n",
    "        어텐션 해더 갯수\n",
    "        \n",
    "    mlp_ratio : float\n",
    "        'dim'에 대한 'MLP' 모듈의 숨겨진 차원 크기를 결정\n",
    "    \n",
    "    qkv_bias : bool\n",
    "        키,쿼리,블럭 바이어스 변수 설정\n",
    "        \n",
    "    p, attn_p : float\n",
    "        드롭아웃 확률\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,dim,n_heads,mlp_ratio=4.0,qkv_bias=True,p=0,attn_p=0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.attn = Attention(dim,n_heads=n_heads,qkv_bias=qkv_bias,attn_p=attn_p,proj_p=p)\n",
    "        self.norm2 = nn.LayerNorm(dim,eps=1e-6)\n",
    "        \n",
    "        ## MLP레이어 임베딩차원은 -> 트랜스포머의 출력 벡터의 4배로   \n",
    "        hidden_feactures = int(dim*mlp_ratio)\n",
    "        self.mlp = MLP(\n",
    "            in_features=dim,\n",
    "            hidden_feactures=hidden_feactures,\n",
    "            out_feactures=dim,\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "          \n",
    "class Vit(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size=256,\n",
    "                 patch_size=16,\n",
    "                 in_chans=3,\n",
    "                 n_classes=1000,\n",
    "                 embed_dim=768,\n",
    "                 depth=1,\n",
    "                 n_heads=12,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 p=0.,\n",
    "                 attn_p=0.,                 \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_embed = patchembed(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            int_chans=in_chans,\n",
    "            embed_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        ## 임베드 벡터의 맨앞에 붙일 클래스 토큰\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1,1,embed_dim))\n",
    "        \n",
    "        ## 포지션 파라미터들\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1,1+self.patch_embed.n_patches,embed_dim))\n",
    "        \n",
    "        self.pos_drop = nn.Dropout(p=p)\n",
    "        \n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    dim = embed_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    p=p,\n",
    "                    attn_p=attn_p,                    \n",
    "                )\n",
    "                for _ in range(depth)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.norm = nn.LayerNorm(embed_dim,eps=1e-6)\n",
    "        self.head = nn.Linear(embed_dim,n_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        ## 배치수\n",
    "        n_samples = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        cls_token = self.cls_token.expand(n_samples,-1,-1) # (배치,1,임베드차원)\n",
    "        \n",
    "        ## cls 토큰을 붙임\n",
    "        x = torch.cat((cls_token,x),dim=1)\n",
    "        \n",
    "        x = x + self.pos_embed # (qocl,1+패치수,임베딩차원)\n",
    "        x = self.pos_drop(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        cls_token_final = x[:,0] # vit 마지막 결과값 가져옴\n",
    "        x = self.head(cls_token_final)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## 데이터 로더\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_size = 32\n",
    "batch_size = 512\n",
    "\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "train_transform = transforms.Compose([transforms.Resize(img_size), transforms.RandomCrop(img_size, padding=2),\n",
    "                                        transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "test_transform = transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean, std)])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "valset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size)\n",
    "valloader = DataLoader(valset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vit(\n",
       "  (patch_embed): patchembed(\n",
       "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 선언\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Vit(img_size=img_size,patch_size=4,in_chans=3,n_classes=10,embed_dim=128,n_heads=8,depth=1)\n",
    "\n",
    "# model = Vit(img_size=img_size,patch_size=4,in_chans=3,n_classes=10)\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0\t98/0]\t loss : 2.3504 \t accuracy : 10.35% \t53/512\n",
      "[0\t98/40]\t loss : 1.8012 \t accuracy : 31.84% \t163/512\n",
      "[0\t98/80]\t loss : 1.6249 \t accuracy : 41.21% \t211/512\n",
      "0 epoch 평균\tloss : 1.806354104256143 \t accuracy : 32.60% \t 16357/50176\n",
      "\n",
      "\n",
      "[1\t98/0]\t loss : 1.6221 \t accuracy : 39.26% \t201/512\n",
      "[1\t98/40]\t loss : 1.4923 \t accuracy : 46.88% \t240/512\n",
      "[1\t98/80]\t loss : 1.4099 \t accuracy : 49.61% \t254/512\n",
      "1 epoch 평균\tloss : 1.493785693937419 \t accuracy : 45.07% \t 22614/50176\n",
      "\n",
      "\n",
      "[2\t98/0]\t loss : 1.3764 \t accuracy : 48.05% \t246/512\n",
      "[2\t98/40]\t loss : 1.4146 \t accuracy : 50.78% \t260/512\n",
      "[2\t98/80]\t loss : 1.3537 \t accuracy : 50.20% \t257/512\n",
      "2 epoch 평균\tloss : 1.3655250206285598 \t accuracy : 50.09% \t 25132/50176\n",
      "\n",
      "\n",
      "[3\t98/0]\t loss : 1.3039 \t accuracy : 51.56% \t264/512\n",
      "[3\t98/40]\t loss : 1.2806 \t accuracy : 54.49% \t279/512\n",
      "[3\t98/80]\t loss : 1.2765 \t accuracy : 52.93% \t271/512\n",
      "3 epoch 평균\tloss : 1.29324436917597 \t accuracy : 52.81% \t 26497/50176\n",
      "\n",
      "\n",
      "[4\t98/0]\t loss : 1.1920 \t accuracy : 57.23% \t293/512\n",
      "[4\t98/40]\t loss : 1.2435 \t accuracy : 57.23% \t293/512\n",
      "[4\t98/80]\t loss : 1.2507 \t accuracy : 53.71% \t275/512\n",
      "4 epoch 평균\tloss : 1.2421459324505868 \t accuracy : 54.99% \t 27590/50176\n",
      "\n",
      "\n",
      "[5\t98/0]\t loss : 1.1552 \t accuracy : 57.23% \t293/512\n",
      "[5\t98/40]\t loss : 1.2350 \t accuracy : 56.84% \t291/512\n",
      "[5\t98/80]\t loss : 1.2051 \t accuracy : 58.20% \t298/512\n",
      "5 epoch 평균\tloss : 1.210776527317203 \t accuracy : 56.18% \t 28187/50176\n",
      "\n",
      "\n",
      "[6\t98/0]\t loss : 1.1416 \t accuracy : 59.18% \t303/512\n",
      "[6\t98/40]\t loss : 1.2154 \t accuracy : 57.62% \t295/512\n",
      "[6\t98/80]\t loss : 1.1926 \t accuracy : 56.84% \t291/512\n",
      "6 epoch 평균\tloss : 1.1816904812443014 \t accuracy : 57.10% \t 28649/50176\n",
      "\n",
      "\n",
      "[7\t98/0]\t loss : 1.1346 \t accuracy : 59.77% \t306/512\n",
      "[7\t98/40]\t loss : 1.1845 \t accuracy : 57.03% \t292/512\n",
      "[7\t98/80]\t loss : 1.1596 \t accuracy : 57.03% \t292/512\n",
      "7 epoch 평균\tloss : 1.1569684695224378 \t accuracy : 58.09% \t 29148/50176\n",
      "\n",
      "\n",
      "[8\t98/0]\t loss : 1.1016 \t accuracy : 59.96% \t307/512\n",
      "[8\t98/40]\t loss : 1.1407 \t accuracy : 58.59% \t300/512\n",
      "[8\t98/80]\t loss : 1.1169 \t accuracy : 60.94% \t312/512\n",
      "8 epoch 평균\tloss : 1.1300458080914555 \t accuracy : 58.92% \t 29563/50176\n",
      "\n",
      "\n",
      "[9\t98/0]\t loss : 1.1167 \t accuracy : 60.35% \t309/512\n",
      "[9\t98/40]\t loss : 1.0758 \t accuracy : 60.16% \t308/512\n",
      "[9\t98/80]\t loss : 1.1364 \t accuracy : 60.55% \t310/512\n",
      "9 epoch 평균\tloss : 1.1134949800919505 \t accuracy : 59.64% \t 29926/50176\n",
      "\n",
      "\n",
      "[10\t98/0]\t loss : 1.0323 \t accuracy : 62.50% \t320/512\n",
      "[10\t98/40]\t loss : 1.1359 \t accuracy : 60.55% \t310/512\n",
      "[10\t98/80]\t loss : 1.1131 \t accuracy : 61.33% \t314/512\n",
      "10 epoch 평균\tloss : 1.0977168064944596 \t accuracy : 60.30% \t 30258/50176\n",
      "\n",
      "\n",
      "[11\t98/0]\t loss : 1.0560 \t accuracy : 61.72% \t316/512\n",
      "[11\t98/40]\t loss : 1.1212 \t accuracy : 58.98% \t302/512\n",
      "[11\t98/80]\t loss : 1.1102 \t accuracy : 60.94% \t312/512\n",
      "11 epoch 평균\tloss : 1.0857127533883468 \t accuracy : 60.70% \t 30457/50176\n",
      "\n",
      "\n",
      "[12\t98/0]\t loss : 0.9708 \t accuracy : 67.58% \t346/512\n",
      "[12\t98/40]\t loss : 1.1235 \t accuracy : 58.79% \t301/512\n",
      "[12\t98/80]\t loss : 1.0383 \t accuracy : 62.30% \t319/512\n",
      "12 epoch 평균\tloss : 1.0575913032706907 \t accuracy : 61.65% \t 30935/50176\n",
      "\n",
      "\n",
      "[13\t98/0]\t loss : 1.0038 \t accuracy : 64.84% \t332/512\n",
      "[13\t98/40]\t loss : 1.0442 \t accuracy : 63.28% \t324/512\n",
      "[13\t98/80]\t loss : 1.0823 \t accuracy : 61.13% \t313/512\n",
      "13 epoch 평균\tloss : 1.0486002965849275 \t accuracy : 62.19% \t 31203/50176\n",
      "\n",
      "\n",
      "[14\t98/0]\t loss : 0.9772 \t accuracy : 65.43% \t335/512\n",
      "[14\t98/40]\t loss : 1.0727 \t accuracy : 62.70% \t321/512\n",
      "[14\t98/80]\t loss : 1.0698 \t accuracy : 64.45% \t330/512\n",
      "14 epoch 평균\tloss : 1.0372941268950089 \t accuracy : 62.65% \t 31434/50176\n",
      "\n",
      "\n",
      "[15\t98/0]\t loss : 0.9645 \t accuracy : 64.45% \t330/512\n",
      "[15\t98/40]\t loss : 1.1005 \t accuracy : 60.35% \t309/512\n",
      "[15\t98/80]\t loss : 1.0340 \t accuracy : 62.50% \t320/512\n",
      "15 epoch 평균\tloss : 1.023832422129962 \t accuracy : 62.77% \t 31497/50176\n",
      "\n",
      "\n",
      "[16\t98/0]\t loss : 0.9620 \t accuracy : 65.82% \t337/512\n",
      "[16\t98/40]\t loss : 1.0877 \t accuracy : 63.28% \t324/512\n",
      "[16\t98/80]\t loss : 1.0508 \t accuracy : 61.33% \t314/512\n",
      "16 epoch 평균\tloss : 1.0244346060314955 \t accuracy : 62.87% \t 31548/50176\n",
      "\n",
      "\n",
      "[17\t98/0]\t loss : 0.9768 \t accuracy : 63.67% \t326/512\n",
      "[17\t98/40]\t loss : 1.0027 \t accuracy : 63.67% \t326/512\n",
      "[17\t98/80]\t loss : 1.0521 \t accuracy : 60.55% \t310/512\n",
      "17 epoch 평균\tloss : 0.9989857892600861 \t accuracy : 63.79% \t 32005/50176\n",
      "\n",
      "\n",
      "[18\t98/0]\t loss : 0.9322 \t accuracy : 65.04% \t333/512\n",
      "[18\t98/40]\t loss : 1.0489 \t accuracy : 61.13% \t313/512\n",
      "[18\t98/80]\t loss : 0.9835 \t accuracy : 64.84% \t332/512\n",
      "18 epoch 평균\tloss : 0.9967575839587622 \t accuracy : 64.00% \t 32115/50176\n",
      "\n",
      "\n",
      "[19\t98/0]\t loss : 0.9336 \t accuracy : 68.36% \t350/512\n",
      "[19\t98/40]\t loss : 1.0410 \t accuracy : 62.50% \t320/512\n",
      "[19\t98/80]\t loss : 0.9746 \t accuracy : 62.70% \t321/512\n",
      "19 epoch 평균\tloss : 0.9869346922757675 \t accuracy : 64.23% \t 32229/50176\n",
      "\n",
      "\n",
      "[20\t98/0]\t loss : 0.9339 \t accuracy : 67.38% \t345/512\n",
      "[20\t98/40]\t loss : 0.9827 \t accuracy : 66.41% \t340/512\n",
      "[20\t98/80]\t loss : 1.0086 \t accuracy : 61.52% \t315/512\n",
      "20 epoch 평균\tloss : 0.9793224553672638 \t accuracy : 64.49% \t 32360/50176\n",
      "\n",
      "\n",
      "[21\t98/0]\t loss : 0.9363 \t accuracy : 68.16% \t349/512\n",
      "[21\t98/40]\t loss : 1.0181 \t accuracy : 61.52% \t315/512\n",
      "[21\t98/80]\t loss : 0.9810 \t accuracy : 64.45% \t330/512\n",
      "21 epoch 평균\tloss : 0.9725847761241757 \t accuracy : 64.86% \t 32546/50176\n",
      "\n",
      "\n",
      "[22\t98/0]\t loss : 0.8928 \t accuracy : 68.75% \t352/512\n",
      "[22\t98/40]\t loss : 1.0239 \t accuracy : 62.70% \t321/512\n",
      "[22\t98/80]\t loss : 0.9328 \t accuracy : 64.65% \t331/512\n",
      "22 epoch 평균\tloss : 0.9625104173105589 \t accuracy : 65.31% \t 32771/50176\n",
      "\n",
      "\n",
      "[23\t98/0]\t loss : 0.8602 \t accuracy : 67.77% \t347/512\n",
      "[23\t98/40]\t loss : 0.9897 \t accuracy : 63.09% \t323/512\n",
      "[23\t98/80]\t loss : 0.9506 \t accuracy : 65.43% \t335/512\n",
      "23 epoch 평균\tloss : 0.9516833984121987 \t accuracy : 65.60% \t 32914/50176\n",
      "\n",
      "\n",
      "[24\t98/0]\t loss : 0.8345 \t accuracy : 68.16% \t349/512\n",
      "[24\t98/40]\t loss : 0.9293 \t accuracy : 67.19% \t344/512\n",
      "[24\t98/80]\t loss : 0.9770 \t accuracy : 64.26% \t329/512\n",
      "24 epoch 평균\tloss : 0.942696789697725 \t accuracy : 65.78% \t 33004/50176\n",
      "\n",
      "\n",
      "[25\t98/0]\t loss : 0.8728 \t accuracy : 68.95% \t353/512\n",
      "[25\t98/40]\t loss : 1.0050 \t accuracy : 64.45% \t330/512\n",
      "[25\t98/80]\t loss : 0.9084 \t accuracy : 65.62% \t336/512\n",
      "25 epoch 평균\tloss : 0.9380323217839609 \t accuracy : 65.93% \t 33083/50176\n",
      "\n",
      "\n",
      "[26\t98/0]\t loss : 0.8608 \t accuracy : 69.14% \t354/512\n",
      "[26\t98/40]\t loss : 0.9389 \t accuracy : 65.04% \t333/512\n",
      "[26\t98/80]\t loss : 0.9135 \t accuracy : 66.02% \t338/512\n",
      "26 epoch 평균\tloss : 0.9330438837713126 \t accuracy : 66.11% \t 33169/50176\n",
      "\n",
      "\n",
      "[27\t98/0]\t loss : 0.8494 \t accuracy : 68.16% \t349/512\n",
      "[27\t98/40]\t loss : 0.9367 \t accuracy : 67.38% \t345/512\n",
      "[27\t98/80]\t loss : 0.8886 \t accuracy : 66.60% \t341/512\n",
      "27 epoch 평균\tloss : 0.9203480567250935 \t accuracy : 66.68% \t 33459/50176\n",
      "\n",
      "\n",
      "[28\t98/0]\t loss : 0.8257 \t accuracy : 69.14% \t354/512\n",
      "[28\t98/40]\t loss : 0.9129 \t accuracy : 67.58% \t346/512\n",
      "[28\t98/80]\t loss : 0.8770 \t accuracy : 67.58% \t346/512\n",
      "28 epoch 평균\tloss : 0.9195777372438083 \t accuracy : 66.58% \t 33409/50176\n",
      "\n",
      "\n",
      "[29\t98/0]\t loss : 0.8666 \t accuracy : 68.95% \t353/512\n",
      "[29\t98/40]\t loss : 0.8855 \t accuracy : 67.38% \t345/512\n",
      "[29\t98/80]\t loss : 0.9247 \t accuracy : 64.84% \t332/512\n",
      "29 epoch 평균\tloss : 0.9121860776628765 \t accuracy : 67.03% \t 33633/50176\n",
      "\n",
      "\n",
      "[30\t98/0]\t loss : 0.8359 \t accuracy : 69.73% \t357/512\n",
      "[30\t98/40]\t loss : 0.8903 \t accuracy : 66.99% \t343/512\n",
      "[30\t98/80]\t loss : 0.9118 \t accuracy : 65.82% \t337/512\n",
      "30 epoch 평균\tloss : 0.9059281720190634 \t accuracy : 66.98% \t 33607/50176\n",
      "\n",
      "\n",
      "[31\t98/0]\t loss : 0.8273 \t accuracy : 70.31% \t360/512\n",
      "[31\t98/40]\t loss : 0.9113 \t accuracy : 68.95% \t353/512\n",
      "[31\t98/80]\t loss : 0.9360 \t accuracy : 64.84% \t332/512\n",
      "31 epoch 평균\tloss : 0.9068638980388645 \t accuracy : 67.10% \t 33670/50176\n",
      "\n",
      "\n",
      "[32\t98/0]\t loss : 0.7817 \t accuracy : 71.29% \t365/512\n",
      "[32\t98/40]\t loss : 0.8876 \t accuracy : 66.02% \t338/512\n",
      "[32\t98/80]\t loss : 0.9010 \t accuracy : 65.82% \t337/512\n",
      "32 epoch 평균\tloss : 0.9002839837755475 \t accuracy : 67.24% \t 33740/50176\n",
      "\n",
      "\n",
      "[33\t98/0]\t loss : 0.8393 \t accuracy : 71.29% \t365/512\n",
      "[33\t98/40]\t loss : 0.9233 \t accuracy : 68.36% \t350/512\n",
      "[33\t98/80]\t loss : 0.8744 \t accuracy : 68.75% \t352/512\n",
      "33 epoch 평균\tloss : 0.8942091276451031 \t accuracy : 67.55% \t 33895/50176\n",
      "\n",
      "\n",
      "[34\t98/0]\t loss : 0.8577 \t accuracy : 70.12% \t359/512\n",
      "[34\t98/40]\t loss : 0.8897 \t accuracy : 68.95% \t353/512\n",
      "[34\t98/80]\t loss : 0.8809 \t accuracy : 68.16% \t349/512\n",
      "34 epoch 평균\tloss : 0.8846193485114039 \t accuracy : 68.00% \t 34122/50176\n",
      "\n",
      "\n",
      "[35\t98/0]\t loss : 0.7835 \t accuracy : 69.92% \t358/512\n",
      "[35\t98/40]\t loss : 0.8805 \t accuracy : 69.53% \t356/512\n",
      "[35\t98/80]\t loss : 0.9200 \t accuracy : 66.41% \t340/512\n",
      "35 epoch 평균\tloss : 0.882555589383962 \t accuracy : 68.00% \t 34119/50176\n",
      "\n",
      "\n",
      "[36\t98/0]\t loss : 0.8537 \t accuracy : 69.14% \t354/512\n",
      "[36\t98/40]\t loss : 0.8875 \t accuracy : 66.99% \t343/512\n",
      "[36\t98/80]\t loss : 0.8904 \t accuracy : 68.36% \t350/512\n",
      "36 epoch 평균\tloss : 0.8731730355291948 \t accuracy : 68.32% \t 34282/50176\n",
      "\n",
      "\n",
      "[37\t98/0]\t loss : 0.8110 \t accuracy : 71.29% \t365/512\n",
      "[37\t98/40]\t loss : 0.9038 \t accuracy : 67.19% \t344/512\n",
      "[37\t98/80]\t loss : 0.8711 \t accuracy : 67.77% \t347/512\n",
      "37 epoch 평균\tloss : 0.8759230776708953 \t accuracy : 68.42% \t 34331/50176\n",
      "\n",
      "\n",
      "[38\t98/0]\t loss : 0.8271 \t accuracy : 68.75% \t352/512\n",
      "[38\t98/40]\t loss : 0.9078 \t accuracy : 66.41% \t340/512\n",
      "[38\t98/80]\t loss : 0.8385 \t accuracy : 68.55% \t351/512\n",
      "38 epoch 평균\tloss : 0.8596033496516094 \t accuracy : 68.81% \t 34526/50176\n",
      "\n",
      "\n",
      "[39\t98/0]\t loss : 0.7819 \t accuracy : 71.68% \t367/512\n",
      "[39\t98/40]\t loss : 0.8592 \t accuracy : 69.53% \t356/512\n",
      "[39\t98/80]\t loss : 0.8295 \t accuracy : 68.95% \t353/512\n",
      "39 epoch 평균\tloss : 0.8649569269345729 \t accuracy : 68.67% \t 34457/50176\n",
      "\n",
      "\n",
      "[40\t98/0]\t loss : 0.7478 \t accuracy : 72.85% \t373/512\n",
      "[40\t98/40]\t loss : 0.8884 \t accuracy : 67.19% \t344/512\n",
      "[40\t98/80]\t loss : 0.8057 \t accuracy : 72.27% \t370/512\n",
      "40 epoch 평균\tloss : 0.8501640436600667 \t accuracy : 69.25% \t 34748/50176\n",
      "\n",
      "\n",
      "[41\t98/0]\t loss : 0.7426 \t accuracy : 74.41% \t381/512\n",
      "[41\t98/40]\t loss : 0.8786 \t accuracy : 67.38% \t345/512\n",
      "[41\t98/80]\t loss : 0.8125 \t accuracy : 73.44% \t376/512\n",
      "41 epoch 평균\tloss : 0.8489185127676747 \t accuracy : 69.31% \t 34777/50176\n",
      "\n",
      "\n",
      "[42\t98/0]\t loss : 0.7666 \t accuracy : 72.46% \t371/512\n",
      "[42\t98/40]\t loss : 0.8530 \t accuracy : 70.12% \t359/512\n",
      "[42\t98/80]\t loss : 0.8190 \t accuracy : 69.73% \t357/512\n",
      "42 epoch 평균\tloss : 0.8459281550378218 \t accuracy : 69.41% \t 34827/50176\n",
      "\n",
      "\n",
      "[43\t98/0]\t loss : 0.7846 \t accuracy : 72.66% \t372/512\n",
      "[43\t98/40]\t loss : 0.8452 \t accuracy : 69.14% \t354/512\n",
      "[43\t98/80]\t loss : 0.8389 \t accuracy : 69.14% \t354/512\n",
      "43 epoch 평균\tloss : 0.8392985159037069 \t accuracy : 69.36% \t 34804/50176\n",
      "\n",
      "\n",
      "[44\t98/0]\t loss : 0.7916 \t accuracy : 70.12% \t359/512\n",
      "[44\t98/40]\t loss : 0.8780 \t accuracy : 67.38% \t345/512\n",
      "[44\t98/80]\t loss : 0.8230 \t accuracy : 69.53% \t356/512\n",
      "44 epoch 평균\tloss : 0.832006163134867 \t accuracy : 69.80% \t 35021/50176\n",
      "\n",
      "\n",
      "[45\t98/0]\t loss : 0.7523 \t accuracy : 74.61% \t382/512\n",
      "[45\t98/40]\t loss : 0.8379 \t accuracy : 70.31% \t360/512\n",
      "[45\t98/80]\t loss : 0.7689 \t accuracy : 72.46% \t371/512\n",
      "45 epoch 평균\tloss : 0.823023853861556 \t accuracy : 70.11% \t 35177/50176\n",
      "\n",
      "\n",
      "[46\t98/0]\t loss : 0.7162 \t accuracy : 75.20% \t385/512\n",
      "[46\t98/40]\t loss : 0.8605 \t accuracy : 72.46% \t371/512\n",
      "[46\t98/80]\t loss : 0.7840 \t accuracy : 71.48% \t366/512\n",
      "46 epoch 평균\tloss : 0.8194629951399196 \t accuracy : 70.27% \t 35260/50176\n",
      "\n",
      "\n",
      "[47\t98/0]\t loss : 0.7738 \t accuracy : 70.90% \t363/512\n",
      "[47\t98/40]\t loss : 0.8334 \t accuracy : 70.70% \t362/512\n",
      "[47\t98/80]\t loss : 0.7808 \t accuracy : 70.12% \t359/512\n",
      "47 epoch 평균\tloss : 0.8213541915222091 \t accuracy : 70.00% \t 35121/50176\n",
      "\n",
      "\n",
      "[48\t98/0]\t loss : 0.7094 \t accuracy : 74.80% \t383/512\n",
      "[48\t98/40]\t loss : 0.8601 \t accuracy : 70.70% \t362/512\n",
      "[48\t98/80]\t loss : 0.7846 \t accuracy : 70.70% \t362/512\n",
      "48 epoch 평균\tloss : 0.8206032040167824 \t accuracy : 70.37% \t 35307/50176\n",
      "\n",
      "\n",
      "[49\t98/0]\t loss : 0.7582 \t accuracy : 72.66% \t372/512\n",
      "[49\t98/40]\t loss : 0.8488 \t accuracy : 70.31% \t360/512\n",
      "[49\t98/80]\t loss : 0.7940 \t accuracy : 70.12% \t359/512\n",
      "49 epoch 평균\tloss : 0.8222133973423315 \t accuracy : 70.01% \t 35130/50176\n",
      "\n",
      "\n",
      "[50\t98/0]\t loss : 0.7406 \t accuracy : 74.41% \t381/512\n",
      "[50\t98/40]\t loss : 0.8497 \t accuracy : 69.53% \t356/512\n",
      "[50\t98/80]\t loss : 0.7830 \t accuracy : 71.09% \t364/512\n",
      "50 epoch 평균\tloss : 0.8100523796616771 \t accuracy : 70.52% \t 35384/50176\n",
      "\n",
      "\n",
      "[51\t98/0]\t loss : 0.7036 \t accuracy : 73.44% \t376/512\n",
      "[51\t98/40]\t loss : 0.8196 \t accuracy : 71.48% \t366/512\n",
      "[51\t98/80]\t loss : 0.7707 \t accuracy : 70.70% \t362/512\n",
      "51 epoch 평균\tloss : 0.8059850572323312 \t accuracy : 70.59% \t 35421/50176\n",
      "\n",
      "\n",
      "[52\t98/0]\t loss : 0.7695 \t accuracy : 72.07% \t369/512\n",
      "[52\t98/40]\t loss : 0.8837 \t accuracy : 69.92% \t358/512\n",
      "[52\t98/80]\t loss : 0.7523 \t accuracy : 70.90% \t363/512\n",
      "52 epoch 평균\tloss : 0.8124387787312874 \t accuracy : 70.28% \t 35264/50176\n",
      "\n",
      "\n",
      "[53\t98/0]\t loss : 0.6935 \t accuracy : 75.39% \t386/512\n",
      "[53\t98/40]\t loss : 0.8172 \t accuracy : 72.85% \t373/512\n",
      "[53\t98/80]\t loss : 0.8028 \t accuracy : 70.51% \t361/512\n",
      "53 epoch 평균\tloss : 0.8061343419308568 \t accuracy : 70.59% \t 35419/50176\n",
      "\n",
      "\n",
      "[54\t98/0]\t loss : 0.7630 \t accuracy : 72.27% \t370/512\n",
      "[54\t98/40]\t loss : 0.8080 \t accuracy : 73.24% \t375/512\n",
      "[54\t98/80]\t loss : 0.7633 \t accuracy : 70.70% \t362/512\n",
      "54 epoch 평균\tloss : 0.7967107977185931 \t accuracy : 71.00% \t 35624/50176\n",
      "\n",
      "\n",
      "[55\t98/0]\t loss : 0.8088 \t accuracy : 71.09% \t364/512\n",
      "[55\t98/40]\t loss : 0.8012 \t accuracy : 71.68% \t367/512\n",
      "[55\t98/80]\t loss : 0.7582 \t accuracy : 71.29% \t365/512\n",
      "55 epoch 평균\tloss : 0.7991073119397066 \t accuracy : 70.80% \t 35523/50176\n",
      "\n",
      "\n",
      "[56\t98/0]\t loss : 0.6939 \t accuracy : 74.22% \t380/512\n",
      "[56\t98/40]\t loss : 0.8104 \t accuracy : 71.09% \t364/512\n",
      "[56\t98/80]\t loss : 0.7777 \t accuracy : 72.46% \t371/512\n",
      "56 epoch 평균\tloss : 0.786439789801228 \t accuracy : 71.34% \t 35796/50176\n",
      "\n",
      "\n",
      "[57\t98/0]\t loss : 0.7233 \t accuracy : 75.98% \t389/512\n",
      "[57\t98/40]\t loss : 0.7882 \t accuracy : 73.24% \t375/512\n",
      "[57\t98/80]\t loss : 0.8058 \t accuracy : 70.12% \t359/512\n",
      "57 epoch 평균\tloss : 0.7878283706246593 \t accuracy : 71.51% \t 35880/50176\n",
      "\n",
      "\n",
      "[58\t98/0]\t loss : 0.7170 \t accuracy : 75.59% \t387/512\n",
      "[58\t98/40]\t loss : 0.7587 \t accuracy : 73.63% \t377/512\n",
      "[58\t98/80]\t loss : 0.7653 \t accuracy : 70.31% \t360/512\n",
      "58 epoch 평균\tloss : 0.7877402269110386 \t accuracy : 71.16% \t 35706/50176\n",
      "\n",
      "\n",
      "[59\t98/0]\t loss : 0.6977 \t accuracy : 75.00% \t384/512\n",
      "[59\t98/40]\t loss : 0.8151 \t accuracy : 72.27% \t370/512\n",
      "[59\t98/80]\t loss : 0.7330 \t accuracy : 72.46% \t371/512\n",
      "59 epoch 평균\tloss : 0.7897097985355221 \t accuracy : 71.26% \t 35756/50176\n",
      "\n",
      "\n",
      "[60\t98/0]\t loss : 0.6836 \t accuracy : 74.02% \t379/512\n",
      "[60\t98/40]\t loss : 0.7901 \t accuracy : 72.27% \t370/512\n",
      "[60\t98/80]\t loss : 0.8157 \t accuracy : 70.70% \t362/512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22263/2193282926.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtotal_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model의 gradient 값을 0으로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \"\"\"\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpadding_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fill\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36m_parse_fill\u001b[0;34m(fill, img, name)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_bands\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_bands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_bands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The number of elements in 'fill' does not match the number of bands of the image ({} != {})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "import torch.optim as optim\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "weight_decay = 0\n",
    "\n",
    "interver=40\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    total_correct = 0\n",
    "    for i,(img,target) in enumerate(trainloader):\n",
    "        optimizer.zero_grad() # model의 gradient 값을 0으로 설정\n",
    "        \n",
    "        outputs = model(img.to(device))\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, target.to(device))\n",
    "        loss.backward() # backward 함수를 호출해 gradient 계산\n",
    "        optimizer.step() # 모델의 학습 파라미터 갱신\n",
    "        \n",
    "        running_loss += loss.item() / len(trainloader)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == target.to(device)).sum().item() \n",
    "        total_correct += correct\n",
    "        \n",
    "        if i % interver ==0:\n",
    "            # print(f'[{epoch}\\t{len(trainloader)}/{i}]\\t loss : {loss:.4f} \\t accuracy : {correct/batch_size*100:.2f}% \\t{correct}/{batch_size}')    \n",
    "            pass\n",
    "\n",
    "    # print(f\"{epoch} epoch 평균\\tloss : {running_loss} \\t accuracy : {total_correct/(batch_size*len(trainloader))*100:.2f}% \\t {total_correct}/{batch_size*len(trainloader)}\")\n",
    "    # print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/onnx/utils.py:286: UserWarning: `add_node_names' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `add_node_names` argument will be ignored.\n",
      "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n",
      "/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/torch/onnx/utils.py:286: UserWarning: `do_constant_folding' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `do_constant_folding` argument will be ignored.\n",
      "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n",
      "/data/mrjaehong/handwriting_gen/pytorch_vit/env/lib/python3.7/site-packages/ipykernel_launcher.py:126: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n",
      "Warning: Shape inference does not support models with experimental operators: ATen\n",
      "Warning: Unsupported operator ATen. No schema registered for this operator.\n"
     ]
    }
   ],
   "source": [
    "# import torch.onnx\n",
    "# torch.onnx.export(model.cpu(),img.cpu(),'./vit.onnx',export_params=False,opset_version=12,\n",
    "#                   operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5320f61119de878fb31c813ca30206b3db486be99fef9b78f5991d1f2558cf1d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
